# VGG-19-Facial-Emotion-Recognition-



![alt text]( https://github.com/pahaht/VGG-19-Facial-Emotion-Recognition-]/blob/main/Images/p-emotions.JPG)





###  *Orverview*
This project focuses on facial emotion recognition using the VGG19 convolutional neural network architecture. 
Facial emotion recognition involves detecting and classifying the emotional expressions conveyed through 
facial expressions captured in images or videos. In this case, we are using VGG19, 
a deep learning model pre-trained on ImageNet, to recognize emotions from facial images.


### *Introduction*
Facial emotion recognition has numerous applications, including:

-Human-computer interaction
-Behavioral analysis
-Mental health monitoring
-Security and surveillance


###  *Model Architecture*
VGG19 is a convolutional neural network architecture introduced by the Visual Geometry Group 
at the University of Oxford. It consists of 19 layers, including convolutional layers,
max-pooling layers, and fully connected layers. VGG19 is known for its simplicity
and effectiveness in image classification tasks.


### *Dataset*
The dataset used for facial emotion recognition typically consists of labeled facial images
with corresponding emotion categories. Common emotion categories include happiness, sadness,
anger, surprise, fear, and disgust. The dataset is divided into training, validation, 
and testing sets for model training, validation, and evaluation, respectively.
![image](https://github.com/pahaht/VGG-19-Facial-Emotion-Recognition-/assets/116424869/ffd0ff6b-5463-4e29-a042-50aaa9f46e09)
